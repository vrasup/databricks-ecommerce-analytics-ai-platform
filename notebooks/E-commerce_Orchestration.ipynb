{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "390f95ae-f5f5-410b-b82f-5ca480e166ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "DropTable"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS workspace.gold.ecommerce_predictions;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d99f95c-2a93-4440-9357-d1939fb3acde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dropped table if it existed: workspace.gold.ecommerce_predictions\n✅ Loading model: ecommerce_purchase_prediction_gb (production)\n✅ Model loaded successfully\n✅ Loaded Gold table: workspace.ecommerce.gold_user_item_features with 4620187 rows\n✅ Feature matrix shape: (4620187, 3)\n✅ Predictions completed\n✅ Predictions joined with identifiers\n✅ Predictions saved to: workspace.gold.ecommerce_predictions\n+---------+------+------------+---------------+--------------+-----------------+------------+----------------+\n|visitorid|itemid|actual_label|predicted_label|predicted_prob|interaction_score|funnel_depth|engagement_score|\n+---------+------+------------+---------------+--------------+-----------------+------------+----------------+\n|   796052|116706|           0|              0|           0.0|                1|           1|               1|\n|   980263|215429|           0|              0|           0.0|                1|           1|               1|\n|   326683| 61926|           0|              0|           0.0|                1|           1|               1|\n|  1014388|324288|           0|              0|           0.0|                1|           1|               1|\n|    74958|284700|           0|              0|           0.0|                1|           1|               1|\n+---------+------+------------+---------------+--------------+-----------------+------------+----------------+\nonly showing top 5 rows\n+-----------------+---------+-------+\n|         col_name|data_type|comment|\n+-----------------+---------+-------+\n|        visitorid|      int|   NULL|\n|           itemid|      int|   NULL|\n|     actual_label|   bigint|   NULL|\n|  predicted_label|   bigint|   NULL|\n|   predicted_prob|   double|   NULL|\n|interaction_score|   bigint|   NULL|\n|     funnel_depth|   bigint|   NULL|\n| engagement_score|      int|   NULL|\n+-----------------+---------+-------+\n\n\uD83C\uDF89 ORCHESTRATION COMPLETE SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# ORCHESTRATOR NOTEBOOK (ALL-IN-ONE)\n",
    "# ----------------------------\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# ----------------------------\n",
    "# 0. Spark Session\n",
    "# ----------------------------\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Drop Existing Predictions Table (Safe)\n",
    "# ----------------------------\n",
    "output_table = \"workspace.gold.ecommerce_predictions\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {output_table}\")\n",
    "print(f\"✅ Dropped table if it existed: {output_table}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Load Production Model from MLflow\n",
    "# ----------------------------\n",
    "model_name = \"ecommerce_purchase_prediction_gb\"\n",
    "model_alias = \"production\"\n",
    "print(f\"✅ Loading model: {model_name} ({model_alias})\")\n",
    "model = mlflow.pyfunc.load_model(f\"models:/{model_name}@{model_alias}\")\n",
    "print(\"✅ Model loaded successfully\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Load Gold Feature Table\n",
    "# ----------------------------\n",
    "gold_table = \"workspace.ecommerce.gold_user_item_features\"\n",
    "df_gold = spark.table(gold_table)\n",
    "print(f\"✅ Loaded Gold table: {gold_table} with {df_gold.count()} rows\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Select Features + Identifiers\n",
    "# ----------------------------\n",
    "feature_cols = [\"interaction_score\", \"funnel_depth\", \"engagement_score\"]\n",
    "id_cols = [\"visitorid\", \"itemid\", \"converted\"]\n",
    "\n",
    "df_input = df_gold.select(id_cols + feature_cols)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Convert to Pandas for Prediction\n",
    "# ----------------------------\n",
    "pdf = df_input.toPandas()\n",
    "X_input = pdf[feature_cols]\n",
    "print(f\"✅ Feature matrix shape: {X_input.shape}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Run Predictions\n",
    "# ----------------------------\n",
    "y_pred_prob = model.predict(X_input)  # returns float probabilities\n",
    "y_pred_label = (y_pred_prob >= 0.5).astype(int)\n",
    "print(\"✅ Predictions completed\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Attach Predictions\n",
    "# ----------------------------\n",
    "pdf[\"actual_label\"] = pdf[\"converted\"].astype(int)\n",
    "pdf[\"predicted_label\"] = y_pred_label\n",
    "pdf[\"predicted_prob\"] = y_pred_prob.astype(float)  # ensure float type\n",
    "\n",
    "# Reorder columns\n",
    "final_pdf = pdf[\n",
    "    [\"visitorid\", \"itemid\", \"actual_label\", \"predicted_label\", \"predicted_prob\"] + feature_cols\n",
    "]\n",
    "\n",
    "# Convert back to Spark DataFrame\n",
    "final_predictions = spark.createDataFrame(final_pdf)\n",
    "print(\"✅ Predictions joined with identifiers\")\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Write to Gold Predictions Table\n",
    "# ----------------------------\n",
    "final_predictions.write.mode(\"overwrite\").saveAsTable(output_table)\n",
    "print(f\"✅ Predictions saved to: {output_table}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 9. Validation: Show first 5 rows and schema\n",
    "# ----------------------------\n",
    "spark.table(output_table).show(5)\n",
    "spark.sql(f\"DESCRIBE TABLE {output_table}\").show()\n",
    "\n",
    "print(\"\uD83C\uDF89 ORCHESTRATION COMPLETE SUCCESSFULLY\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5571365192882537,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "E-commerce_Orchestration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}